---
title: "DATA_621_HW5"
author: "Sarah Wigodsky"
date: "December 4, 2018"
output: html_document
---

##DATA EXPLORATION

```{r load_data, echo=FALSE}
wine <- read.csv("https://raw.githubusercontent.com/swigodsky/Data621/master/wine-training-data.csv", stringsAsFactors = FALSE)
head(wine)
#nrow(wine)
meantarget <- round(mean(wine$TARGET))
```

The data set consists of 12,795 records of different wines.  The variables are mostly related to the chemical properties of the wines.  The goal is to use the variables to create a model that predicts the number of cases of that wine that would be purchased by distribution companies.

The following is a list of variable that will be used to predict the number of cases:

  - AcidIndex - Proprietary method of testing total acidity of wine by using a weighted average
  - Alcohol - Alcohol Content
  - Chlorides - Chloride content of wine
  - CitricAcid - Citric Acid Content
  - Density - Density of Wine
  - FixedAcidity - Fixed Acidity of Wine
  - FreeSulfurDioxide - Sulfur Dioxide content of wine
  - LabelAppeal - Marketing Score indicating the appeal of label design for consumers. High numbers suggest customers like the label design. Negative numbers suggest customes don't like the design.
  - ResidualSugar - Residual Sugar of wine
  - STARS - Wine rating by a team of experts. 4 Stars = Excellent, 1 Star = Poor 
  - Sulphates - Sulfate content of wine
  - TotalSulfurDioxide - Total Sulfur Dioxide of Wine
  - VolatileAcidity - Volatile Acid content of wine
  - pH - pH of wine

The following are sumamry statistics for each of the variables described above:
```{r summary_statistics, echo=FALSE}
wine_index_removed <- wine[-1]
summary(wine_index_removed)
```

###Correlation of Variables
The following are the correlation values between each of the variables. The closer the correlation is to 1 or -1, the more highly correlated the variables.
```{r correlation, echo=FALSE, fig.width=10, message=FALSE}
library(corrplot)
correlation <- cor(wine_index_removed, method = "pearson",use="complete.obs")
#correlation
corrplot(correlation, type="upper", method="color")
```




The target variable is positively correlated with LabelAppeal and STARS.  The target variable is negavitely correlated with VolatileAcidity and Acid Index.

In terms of the independent variables, AcidIndex and FixedAcidity are positively correlated.  This makes sense as they are both measuring acidity.

STARS and LabelAppeal are positively correlated.  Perhaps the appearance affects the number of stars the wine is given.  Or perhaps that better wines tend to make more effort on their label.

#####Investigating the Relationship Between AcidIndex and FixedAcidity
```{r acid_investigation, echo=FALSE}
plot(wine$AcidIndex, ylab="Acid Index")
hist(wine$AcidIndex, xlab="Acid Index",main="Histogram of Acid Index")
boxplot(wine$AcidIndex, main="Acid Index")

plot(wine$FixedAcidity, ylab="Fixed Acidity")
hist(wine$FixedAcidity, xlab="Fixed Acidity",main="Histogram of Fixed Acidity")
boxplot(wine$FixedAcidity, main="Fixed Acidity")

plot(wine$FixedAcidity,wine$AcidIndex, xlab="Fixed Acidity", ylab="Acid Index", main="Relationship Between Acid Index and Fixed Acidity")
abline(lm(wine$AcidIndex~wine$FixedAcidity),col="red")
```

Acid index is an integer value, which ranges between 4 and 17.  Its mean is 7.8 and its median is 8.  It is skewed to the right. Wines with acid indeces 5 and below as well as those with indeces 10 and above are outliers.

Fixed Acidity is a decimal value, which ranges between -18.1 and 34.4.  By far most of the values lie between 5 and 10.  The mean and median are both about 7, and the other values are equally distributed above and below.  Fixed Acidities above 15 and below -1 are outliers.

The graph of acid index vs. fixed acidity displays a slight positive trend, but it is not as clear of a relationship as I was expecting.


#####Investigating the Relationship Between STARS and LabelAppeal
```{r acid_investigation, echo=FALSE}
hist(wine$STARS, xlab="Stars",main="Histogram of Stars")
boxplot(wine$STARS, main="Stars")

hist(wine$LabelAppeal, xlab="Label Appeal",main="Histogram of Label Appeal")
boxplot(wine$LabelAppeal, main="Label Appeal")

plot(wine$LabelAppeal,wine$STARS, xlab="Label Appeal", ylab="Stars", main="Relationship Between Label Appeal and Stars")
abline(lm(wine$STARS~wine$LabelAppeal),col="red")
```

Wines are rated with stars ranging as integers between 1 and 4.  Most wines are given ratings of 1 or 2. There are no outliers.

Label appeal is an integer rating between -2 and 2.  The distribution looks normal and is centered at 0. There are no outliers.

There is a positive trend between label appeal and the number of stars.

###Missing Values
There are missing values for Residual Sugar, Chlorides, FreeSulfurDioxide, TotalSulfurDioxide, pH, Sulphates, Alcohol and STARS.

```{r missing values, echo=FALSE}
plot(wine$ResidualSugar, ylab="Residual Sugar")
hist(wine$ResidualSugar, xlab="Residual Sugar",main="Histogram of Residual Sugar")
boxplot(wine$ResidualSugar, main="Residual Sugar")

plot(wine$Chlorides, ylab="Chlorides")
hist(wine$Chlorides, xlab="Chlorides",main="Histogram of Chlorides")
boxplot(wine$Chlorides, main="Chlorides")

plot(wine$FreeSulfurDioxide, ylab="Free Sulfur Dioxide")
hist(wine$FreeSulfurDioxide, xlab="Free Sulfur Dioxide",main="Histogram of Free Sulfur Dioxide")
boxplot(wine$FreeSulfurDioxide, main="Free Sulfur Dioxide")

plot(wine$TotalSulfurDioxide, ylab="Total Sulfur Dioxide")
hist(wine$TotalSulfurDioxide, xlab="Total Sulfur Dioxide",main="Histogram of Total Sulfur Dioxide")
boxplot(wine$TotalSulfurDioxide, main="Total Sulfur Dioxide")

plot(wine$pH, ylab="pH")
hist(wine$pH, xlab="pH",main="Histogram of pH")
boxplot(wine$pH, main="pH")

plot(wine$Sulphates, ylab="Sulphates")
hist(wine$Sulphates, xlab="Sulphates",main="Histogram of Sulphates")
boxplot(wine$Sulphates, main="Sulphates")

plot(wine$Alcohol, ylab="Alcohol")
hist(wine$Alcohol, xlab="Alcohol",main="Histogram of Alcohol")
boxplot(wine$Alcohol, main="Alcohol")
```

The distributions for Residual Sugar, Chlorides, FreeSulfurDioxide, TotalSulfurDioxide, pH, Sulphates, Alcohol have most of the values clustered around the mean.  

##DATA PREPARATION
Because the variables that have missing values are most values near the mean, I will impute the mean for the missing values.
```{r impute_mean, echo=FALSE}
wine_imputed <- wine_index_removed

mean_res_sugar <- mean(wine_imputed$ResidualSugar, na.rm=T)
wine_imputed$ResidualSugar[is.na(wine_imputed$ResidualSugar)] <- mean_res_sugar

mean_chlorides <- mean(wine_imputed$Chlorides, na.rm=T)
wine_imputed$Chlorides[is.na(wine_imputed$Chlorides)] <- mean_chlorides

mean_freesulfdiox <- mean(wine_imputed$FreeSulfurDioxide, na.rm=T)
wine_imputed$FreeSulfurDioxide[is.na(wine_imputed$FreeSulfurDioxide)] <- mean_freesulfdiox

mean_pH <- mean(wine_imputed$pH, na.rm=T)
wine_imputed$pH[is.na(wine_imputed$pH)] <- mean_pH

mean_totsulfdiox <- mean(wine_imputed$TotalSulfurDioxide, na.rm=T)
wine_imputed$TotalSulfurDioxide[is.na(wine_imputed$TotalSulfurDioxide)] <- mean_totsulfdiox

mean_sulphates <- mean(wine_imputed$Sulphates, na.rm=T)
wine_imputed$Sulphates[is.na(wine_imputed$Sulphates)] <- mean_sulphates

mean_alcohol <- mean(wine_imputed$Alcohol, na.rm=T)
wine_imputed$Alcohol[is.na(wine_imputed$Alcohol)] <- mean_alcohol

mean_stars <- mean(wine_imputed$STARS, na.rm=T)
wine_imputed$STARS[is.na(wine_imputed$STARS)] <- mean_stars
```

To address the correlation between the number of stars and label appeal, I will combine those variables by adding the values together.
```{r stars_label, echo=FALSE}
stars_label <- wine_imputed$STARS + wine_imputed$LabelAppeal
wine_imputed <- cbind(wine_imputed, stars_label)
wine_imputed <-subset(wine_imputed, select=-c(STARS, LabelAppeal))
```

##Build Models
####Creating a Test Set and Training Set
```{r model1_training_testing, echo=FALSE, cache=TRUE}
set.seed(15)
n <- nrow(wine_imputed)
shuffle_df1 <- wine_imputed[sample(n),]
train_indeces <- 1:round(0.6*n)
train1 <- shuffle_df1[train_indeces,]
test_indeces <- (round(.6*n)+1):n
test1 <- shuffle_df1[test_indeces,]
```

####Backward Elimination - Poisson Regression Model 1
```{r backward-elimination1, echo=FALSE}
poisson1 <- glm(TARGET ~ ., data=train1, family="poisson")
summary(poisson1)
```
Residual Sugar has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_res_sugar1, echo=FALSE}
poisson1 <- update(poisson1, .~. -ResidualSugar, data = train1, family="poisson")
summary(poisson1)
```

Citric Acid has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_citricacid1, echo=FALSE}
poisson1 <- update(poisson1, .~. -CitricAcid, data = train1, family="poisson")
summary(poisson1)
```

Fixed Acidity has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_fixedacidity1, echo=FALSE}
poisson1 <- update(poisson1, .~. -FixedAcidity, data = train1, family="poisson")
summary(poisson1)
```

The following variables have a positive effect on the number of cases chosen by distributors to buy: Free Sulfur Dioxide, Total Sulfur Dioxide, Alcohol and the Number of Stars and Label Appeal.

The following variables have a negative effect on the number of cases chosen by distributors to buy: Volatile Acidity, Chlorides, Density, pH, Sulphates, and Acid Index.

```{r fxns, echo=FALSE}
acc <- function(pred, test){
  totalnum <- length(pred) 
  numRight <- length(which(pred==test$TARGET))
  accuracy <- numRight/totalnum
  return(accuracy)
} 

accplusminus1 <- function(pred, test){
  totalnum <- length(pred) 
  numRightish <- length(which(pred==test$TARGET+1|pred==test$TARGET-1|pred==test$TARGET))
  accuracy1 <- numRightish/totalnum
  return(accuracy1)
} 

err <- function(pred, test){
  totalnum <- length(pred) 
  numWrong <- length(which(pred!=test$TARGET))
  error <- numWrong/totalnum
  return(error)
} 

```

####Prediction from Poisson Model 1

```{r pred_model1, echo=FALSE}

pred_p1 <- predict(poisson1, newdata=test1, type="response")
pred_p1 <- round(pred_p1)
table(pred=pred_p1, true=test1$TARGET)
accuracy <- acc(pred_p1,test1)
print(accuracy)
print(accplusminus1(pred_p1,test1))
```

Model 1 predicts the number of cases of wine bought 25% of the time.  Model 1 predicts the number of cases within 1 64% of the time.  

```{r rmes1, echo=FALSE}
error1 <- pred_p1-test1$TARGET
rmse1 <- sqrt(mean(error1^2))
rmse1
```
On average, the predicion for the number of cases of wine purchased, is off by 1.6 cases.

###Model 2 - Negative Binomial Regression 
To build a second model, I will start with only the variables that displayed correlation with the target variable.

```{r model2, echo=FALSE}
wine2 <- wine_index_removed
wine2 <- subset(wine2, select=c(TARGET,VolatileAcidity, Chlorides,Density,Sulphates,Alcohol, AcidIndex,STARS, LabelAppeal))
```


####Creating a Test Set and Training Set
```{r model1_training_testing, echo=FALSE, cache=TRUE}
set.seed(15)
n <- nrow(wine2)
shuffle_df2 <- wine2[sample(n),]
train_indeces <- 1:round(0.6*n)
train2 <- shuffle_df2[train_indeces,]
test_indeces <- (round(.6*n)+1):n
test2 <- shuffle_df2[test_indeces,]
```

```{r backward-elimination2, echo=FALSE}
library(MASS)
nb2 <- glm.nb(TARGET ~ ., data=train2)
summary(nb2)
```

Residual Sugar has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_sulphates2, echo=FALSE}
nb2 <- update(nb2, .~. -Sulphates, data = train2)
summary(nb2)
```

Density has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_density2, echo=FALSE}
nb2 <- update(nb2, .~. -Density, data = train2)
summary(nb2)
```

Fixed Acidity has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_chlorides2, echo=FALSE}
nb2 <- update(nb2, .~. -Chlorides, data = train2)
summary(nb2)
```

The following variables have a positive impact on the number of cases of wine bought: alcohol, stars and label appeal.
The following variables have a negative impact on the number of cases of wine bought: volatile acidity and acid index.

####Prediction from Negative Binomial Regression- Model 2
Any values that are not predicted by the model, will be imputed to be the mean of the number of cases bought.
```{r pred_model2, echo=FALSE}

pred_nb2 <- predict(nb2, newdata=test2, type="response")
pred_nb2[is.na(pred_nb2)] <- meantarget
pred_nb2 <- round(pred_nb2)
table(pred=pred_nb2, true=test2$TARGET)
accuracy <- acc(pred_nb2,test2)
print(accuracy)
print(accplusminus1(pred_nb2,test2))
```

This model predicts the number of cases purchased 33% of the time.  This model predicts the number of cases bought within 1, 70% of the time.


```{r rmes2, echo=FALSE}
error2 <- pred_nb2-test2$TARGET
rmse2 <- sqrt(mean(error2^2))
rmse2
```
On average, the predicion for the number of cases of wine purchased, is off by 1.6 cases.


####Multiple Linear Regression Model - Model 3
I will build model 3 using the same data set as model 2, but I will combine the variables stars and label appeal by adding them.
```{r model3, echo=FALSE}
wine3 <- wine2
stars_label <- wine3$STARS + wine3$LabelAppeal
wine3 <- cbind(wine3, stars_label)
wine3 <-subset(wine3, select=-c(STARS, LabelAppeal))
```

####Creating a Test Set and Training Set
```{r model1_training_testing, echo=FALSE, cache=TRUE}
set.seed(15)
n <- nrow(wine3)
shuffle_df3 <- wine3[sample(n),]
train_indeces <- 1:round(0.6*n)
train3 <- shuffle_df3[train_indeces,]
test_indeces <- (round(.6*n)+1):n
test3 <- shuffle_df3[test_indeces,]
```

####Backward Elimination
```{r backward-elimination3, echo=FALSE}
lm3 <- lm(train3$TARGET ~., data=train3)
summary(lm3)
```

Sulphates has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_sulphates3, echo=FALSE}
lm3 <- update(lm3, .~. -Sulphates, data = train3)
summary(lm3)
```

Density has the (highest p value) lowest affect on the target and will be removed next.  
```{r remove_density3, echo=FALSE}
lm3 <- update(lm3, .~. -Density, data = train3)
summary(lm3)
```

```{r res3, echo=FALSE}
plot(fitted(lm3),resid(lm3))
qqnorm(resid(lm3))
qqline(resid(lm3))
```

####Prediction from Model 3
If the model does not predict a value for the TARGET, I will impute the mean value for the target.
The root mean square error from model 3 is
```{r rmse3, echo=FALSE}
pred3 <- predict(lm3, newdata=test3, type="response")
pred3[pred3<0]<-0
pred3[is.na(pred3)] <- meantarget
pred3 <- round(pred3)
error <- pred3-test3$TARGET
head(pred3)
rmse3 <- sqrt(mean(error^2))
rmse3
```

On average, the predicion for the number of cases of wine purchased, is off by 1.6 cases.


```{r pred_model3, echo=FALSE}
table(pred=pred3, true=test3$TARGET)
accuracy <- acc(pred3,test3)
print(accuracy)
print(accplusminus1(pred3,test3))
```

The model predicts the correct number of cases bought 33% of the time.  The model is off by 1 case 70% of the time.